import os
import re
import shutil
import requests
import csv
from bs4 import BeautifulSoup
from urllib.parse import urlsplit
from pathlib import Path
from tqdm import tqdm

# CSVè®°å½•æ–‡ä»¶è·¯å¾„
IMAGE_RECORD_FILE = "image_download_records.csv"

# æ–°å»ºç›®å½•
os.makedirs("newdata/img", exist_ok=True)

# åŠ è½½å·²ä¸‹è½½çš„å›¾ç‰‡è®°å½•
def load_image_records() -> set:
    records = set()
    if Path(IMAGE_RECORD_FILE).exists():
        with open(IMAGE_RECORD_FILE, 'r', encoding='utf-8', newline='') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row['status'] == '1':  # åªæ£€æŸ¥æˆåŠŸä¸‹è½½çš„
                    img_path = row['image_path']
                    html_file = row['html_file']
                    # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦ä»ç„¶å­˜åœ¨
                    if os.path.exists(img_path):
                        records.add((img_path, html_file))
    return records

# è®°å½•å›¾ç‰‡ä¸‹è½½çŠ¶æ€
def record_image_download(image_path: str, html_file: str, status: int, error_msg: str = ""):
    file_exists = Path(IMAGE_RECORD_FILE).exists()
    with open(IMAGE_RECORD_FILE, 'a', encoding='utf-8', newline='') as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(['image_path', 'html_file', 'status', 'error_message'])
        writer.writerow([image_path, html_file, status, error_msg])

# ç¬¬ä¸€é˜¶æ®µï¼šé¢„å¤„ç† HTML
html_dir = "data"
new_html_dir = "newdata"
new_img_dir = "newdata/img"

# åŠ è½½å·²ä¸‹è½½çš„å›¾ç‰‡è®°å½•
image_records = load_image_records()
print(f"ğŸ“‹ å·²åŠ è½½ {len(image_records)} æ¡å›¾ç‰‡ä¸‹è½½è®°å½•")

def download_image(url, dest_dir, html_file, pbar=None):
    # åˆ›å»ºä»¥HTMLæ–‡ä»¶åå‘½åçš„å­ç›®å½•
    html_name = os.path.splitext(html_file)[0]  # å»æ‰.htmlåç¼€
    html_img_dir = os.path.join(dest_dir, html_name)
    os.makedirs(html_img_dir, exist_ok=True)
    
    filename = os.path.basename(urlsplit(url).path)
    target = os.path.join(html_img_dir, filename)
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»ä¸‹è½½è¿‡
    relative_path = os.path.relpath(target, os.getcwd())
    if (relative_path, html_file) in image_records:
        if pbar:
            pbar.set_description(f"â­ï¸ è·³è¿‡: {filename}")
        return os.path.basename(target)
    
    try:
        if pbar:
            pbar.set_description(f"ğŸ“¥ ä¸‹è½½: {filename}")
        resp = requests.get(url, timeout=10)
        if resp.status_code == 200:
            with open(target, "wb") as f:
                f.write(resp.content)
            if pbar:
                pbar.set_description(f"âœ… æˆåŠŸ: {filename}")
            # è®°å½•æˆåŠŸä¸‹è½½
            record_image_download(relative_path, html_file, 1)
            return os.path.basename(target)
        else:
            if pbar:
                pbar.set_description(f"âŒ å¤±è´¥: {filename}")
            record_image_download(relative_path, html_file, 0, f"HTTP {resp.status_code}")
    except Exception as e:
        if pbar:
            pbar.set_description(f"âŒ å¼‚å¸¸: {filename}")
        record_image_download(relative_path, html_file, 0, str(e))
    return None

# è·å–éœ€è¦å¤„ç†çš„HTMLæ–‡ä»¶åˆ—è¡¨
html_files = [f for f in os.listdir(html_dir) if f.endswith(".html")]
print(f"ğŸ“„ æ‰¾åˆ° {len(html_files)} ä¸ªHTMLæ–‡ä»¶éœ€è¦å¤„ç†")

# ä¸»å¤„ç†å¾ªç¯
for file in tqdm(html_files, desc="å¤„ç†HTMLæ–‡ä»¶", unit="file"):
    path = os.path.join(html_dir, file)
    
    with open(path, "r", encoding="utf-8") as f:
        html = f.read()
    soup = BeautifulSoup(html, "html.parser")

    # æ‰¾åˆ°æ‰€æœ‰éœ€è¦ä¸‹è½½çš„å›¾ç‰‡
    images_to_download = []
    for img in soup.find_all("img"):
        src = img.get("src", "")
        if src.startswith("http"):
            images_to_download.append((img, src))

    all_local = True
    # ä¸‹è½½å›¾ç‰‡è¿›åº¦æ¡
    if images_to_download:
        pbar = tqdm(images_to_download, desc=f"ä¸‹è½½å›¾ç‰‡ ({file})", unit="img", leave=False)
        for img, src in pbar:
            filename = download_image(src, new_img_dir, file, pbar)
            if filename:
                html_name = os.path.splitext(file)[0]  # å»æ‰.htmlåç¼€
                img["src"] = f"img/{html_name}/{filename}"
            else:
                all_local = False
                break
        pbar.close()

    if not all_local:
        tqdm.write(f"âš ï¸ è·³è¿‡æ–‡ä»¶ {file}ï¼Œå­˜åœ¨ä¸‹è½½å¤±è´¥çš„å›¾ç‰‡")
        continue

    # æ‰€æœ‰imgæ ‡ç­¾éƒ½ä¸ºæœ¬åœ°ï¼Œæ›¿æ¢è·¯å¾„ä¸ºwordpressçš„å›¾ç‰‡è·¯å¾„
    new_soup = BeautifulSoup(str(soup), "html.parser")
    for img in new_soup.find_all("img"):
        src = img.get("src", "")
        if src.startswith("img/"):
            # ä»è·¯å¾„ä¸­æå–æ–‡ä»¶åï¼ˆå»æ‰img/ç›®å½•éƒ¨åˆ†ï¼‰
            fname = os.path.basename(src)
            img["src"] = f"/wp-content/uploads/{fname}"

    with open(os.path.join(new_html_dir, file), "w", encoding="utf-8") as f:
        f.write(str(new_soup))
    tqdm.write(f"âœ… å®Œæˆå¤„ç†: {file}")

input("âœ… ç¬¬ä¸€æ­¥å®Œæˆï¼ŒæŒ‰ä»»æ„é”®ç»§ç»­æ‰§è¡Œç¬¬äºŒæ­¥...")
