import os
import random
import datetime
import math,re
import xml.etree.ElementTree as ET
from xml.dom import minidom
from bs4 import BeautifulSoup
from pathlib import Path

new_html_dir = "newdata" # one-stepå¾—åˆ°çš„ç›®å½•
rss_dir = "rss" # ç”Ÿæˆçš„rssæ–‡ä»¶ç›®å½•
posted_rss_dir = "posted_rss" # å·²æäº¤çš„rssæ–‡ä»¶ç›®å½•
base_link = "https://cscodetutor.com/" #å¡«å…¥ç½‘ç«™é¦–é¡µåœ°å€
batch_size = 30 #æ¯å¤šå°‘ä¸ªhtmlç»„æˆä¸€ä¸ªrss
update_date = "2025-07-19" # æ–°æ–‡ç« æ›´æ–°æ—¥æœŸ
add_update = False # æ˜¯å¦è¿›è¡Œé‡å¤åˆ¤æ–­ï¼ŒTrueä¸ºè¿›è¡Œé‡å¤åˆ¤æ–­ï¼ŒFalseä¸ºä¸è¿›è¡Œï¼ˆä¼šå½±å“æ—¥æœŸç”Ÿæˆæ–¹å¼ï¼‰
os.makedirs(rss_dir, exist_ok=True)

# åŠ è½½å·²æäº¤çš„HTMLæ–‡ä»¶è®°å½•
def load_posted_html_files():
    """
    ä»posted_rssç›®å½•ä¸‹çš„æ‰€æœ‰RSSæ–‡ä»¶ä¸­æå–å·²æäº¤çš„HTMLæ–‡ä»¶å
    è¿”å›ä¸€ä¸ªé›†åˆï¼ŒåŒ…å«æ‰€æœ‰å·²æäº¤çš„HTMLæ–‡ä»¶åï¼ˆä¸å«.htmlåç¼€ï¼‰
    """
    posted_files = set()
    
    if not os.path.exists(posted_rss_dir):
        print(f"ğŸ“ {posted_rss_dir} ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡å·²æäº¤æ–‡ä»¶æ£€æŸ¥")
        return posted_files
    
    rss_files = [f for f in os.listdir(posted_rss_dir) if f.endswith('.xml')]
    if not rss_files:
        print(f"ğŸ“ {posted_rss_dir} ç›®å½•ä¸‹æ²¡æœ‰RSSæ–‡ä»¶")
        return posted_files
    
    print(f"ğŸ“‹ å¼€å§‹åŠ è½½å·²æäº¤çš„RSSæ–‡ä»¶...")
    
    for rss_file in rss_files:
        rss_path = os.path.join(posted_rss_dir, rss_file)
        try:
            tree = ET.parse(rss_path)
            root = tree.getroot()
            
            # æŸ¥æ‰¾æ‰€æœ‰itemå…ƒç´ 
            for item in root.findall('.//item'):
                link_elem = item.find('link')
                if link_elem is not None and link_elem.text:
                    # ä»é“¾æ¥ä¸­æå–HTMLæ–‡ä»¶å
                    link = link_elem.text
                    if link.startswith(base_link):
                        # æå–æ–‡ä»¶åéƒ¨åˆ†ï¼ˆå»æ‰base_linkå’Œ.htmlåç¼€ï¼‰
                        filename = link.replace(base_link, '').replace('.html', '')
                        posted_files.add(filename)
                        print(f"  ğŸ“„ å·²æäº¤: {filename}")
            
        except Exception as e:
            print(f"âŒ è§£æRSSæ–‡ä»¶ {rss_file} æ—¶å‡ºé”™: {e}")
            continue
    
    print(f"âœ… å…±åŠ è½½ {len(posted_files)} ä¸ªå·²æäº¤çš„HTMLæ–‡ä»¶")
    return posted_files

def random_date(year):
    """
    æ ¹æ®å¹´ä»½ç”Ÿæˆè¯¥å¹´çš„æŸä¸ªéšæœºæ—¥æœŸ
    """
    start = datetime.date(year, 1, 1)
    end = datetime.date(year, 12, 31)
    rand_day = start + datetime.timedelta(days=random.randint(0, (end - start).days))
    rand_time = datetime.time(hour=random.randint(0, 23), minute=random.randint(0, 59))
    return datetime.datetime.combine(rand_day, rand_time).strftime("%a, %d %b %Y %H:%M:%S +0000")

def random_date_range(start_date_str, end_date_str):
    """
    æ ¹æ®æŒ‡å®šçš„æ—¥æœŸèŒƒå›´ç”Ÿæˆéšæœºæ—¥æœŸ
    """
    start_date = datetime.datetime.strptime(start_date_str, "%Y-%m-%d").date()
    end_date = datetime.datetime.strptime(end_date_str, "%Y-%m-%d").date()
    rand_day = start_date + datetime.timedelta(days=random.randint(0, (end_date - start_date).days))
    rand_time = datetime.time(hour=random.randint(0, 23), minute=random.randint(0, 59))
    return datetime.datetime.combine(rand_day, rand_time).strftime("%a, %d %b %Y %H:%M:%S +0000")

def extract_between_tags(filepath):
    inside = False
    collected = []
    with open(filepath, "r", encoding="utf-8") as f:
        for line in f:
            if '</header>' in line:
                inside = True
                continue
            if '<footer class="post-footer">' in line:
                break
            if inside:
                collected.append(line.strip())
    raw_html = ''.join(collected).replace('\n', '')
    # æ¸…ç†éæ³•å­—ç¬¦ï¼ˆå¦‚æ§åˆ¶å­—ç¬¦ï¼‰
    clean_html = re.sub(r'[^\x09\x0A\x0D\x20-\x7E\u4E00-\u9FA5\u3000-\u303F\uFF00-\uFFEF]', '', raw_html)
    return clean_html

def main():
    # æ ¹æ®add_updateå‚æ•°å†³å®šæ˜¯å¦åŠ è½½å·²æäº¤çš„HTMLæ–‡ä»¶
    posted_files = set()
    if add_update:
        posted_files = load_posted_html_files()
        print(f"ğŸ” å¯ç”¨é‡å¤åˆ¤æ–­æ¨¡å¼")
    else:
        print(f"ğŸš€ è·³è¿‡é‡å¤åˆ¤æ–­æ¨¡å¼")
    
    # è·å–æ‰€æœ‰HTMLæ–‡ä»¶å¹¶æ ¹æ®add_updateå‚æ•°å†³å®šæ˜¯å¦è¿‡æ»¤
    all_files = [f for f in os.listdir(new_html_dir) if f.endswith(".html")]
    available_files = []
    
    if add_update:
        # è¿‡æ»¤æ‰å·²æäº¤çš„æ–‡ä»¶
        for file in all_files:
            html_name = file.replace('.html', '')
            if html_name not in posted_files:
                available_files.append(file)
            else:
                print(f"â­ï¸ è·³è¿‡å·²æäº¤çš„æ–‡ä»¶: {file}")
    else:
        # ä¸è¿›è¡Œé‡å¤åˆ¤æ–­ï¼Œä½¿ç”¨æ‰€æœ‰æ–‡ä»¶
        available_files = all_files
    
    print(f"ğŸ“„ æ€»æ–‡ä»¶æ•°: {len(all_files)}, å¯ç”¨æ–‡ä»¶æ•°: {len(available_files)}")
    
    if not available_files:
        if add_update:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„HTMLæ–‡ä»¶ï¼Œæ‰€æœ‰æ–‡ä»¶éƒ½å·²æäº¤è¿‡")
        else:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„HTMLæ–‡ä»¶")
        return
    
    # æ‰“ä¹±å¯ç”¨æ–‡ä»¶é¡ºåº
    random.shuffle(available_files)
    total_batches = math.ceil(len(available_files) / batch_size)
    
    # æ ¹æ®add_updateå‚æ•°å†³å®šæ—¥æœŸç”Ÿæˆç­–ç•¥
    if add_update:
        # ä½¿ç”¨update_dateåˆ°ä»Šå¤©éšæœºé€‰æ‹©æ—¥æœŸ
        today = datetime.date.today()
        today_str = today.strftime("%Y-%m-%d")
        print(f"ğŸ“… æ–°æ–‡ç« æ—¥æœŸèŒƒå›´: {update_date} åˆ° {today_str}")
    else:
        # æ„å»ºå¹´ä»½æ± ,ç¡®ä¿æ¯ä¸ªå¹´ä»½éƒ½æ¯”è¾ƒå‡åŒ€
        years = list(range(2016, 2026))
        year_pool = (years * ((len(available_files) // len(years)) + 1))[:len(available_files)]
        random.shuffle(year_pool)
        print(f"ğŸ“… ä½¿ç”¨å†å²å¹´ä»½æ± ç”Ÿæˆæ—¥æœŸ")
    
    print(f"ğŸ”„ å°†ç”Ÿæˆ {total_batches} ä¸ªRSSæ‰¹æ¬¡")
    
    for batch_idx in range(total_batches):
        batch_files = available_files[batch_idx * batch_size : (batch_idx + 1) * batch_size]
        rss_root = ET.Element("rss", version="2.0")
        channel = ET.SubElement(rss_root, "channel")

        ET.SubElement(channel, "title").text = f"Batch {batch_idx + 1}"
        ET.SubElement(channel, "link").text = base_link
        ET.SubElement(channel, "description").text = "WordPress RSS Import Batch"

        for file_idx, filename in enumerate(batch_files):
            with open(os.path.join(new_html_dir, filename), "r", encoding="utf-8") as f:
                html = f.read()
            soup = BeautifulSoup(html, "html.parser")

            title_tag = soup.find("h1", class_="post-title")
            title = title_tag.get_text(strip=True) if title_tag else "Untitled"

            # æå– <header> åˆ° <footer> ä¹‹é—´ HTML
            description_html = extract_between_tags(os.path.join(new_html_dir, filename))

            item = ET.SubElement(channel, "item")
            ET.SubElement(item, "title").text = title
            ET.SubElement(item, "link").text = base_link + filename.replace(".html", "")
            
            # æ ¹æ®add_updateå‚æ•°é€‰æ‹©æ—¥æœŸç”Ÿæˆæ–¹å¼
            if add_update:
                ET.SubElement(item, "pubDate").text = random_date_range(update_date, today_str)
            else:
                ET.SubElement(item, "pubDate").text = random_date(year_pool.pop())
                
            ET.SubElement(item, "description").text = "<![CDATA[" + description_html + "]]>"

        rss_path = os.path.join(rss_dir, f"rss_{batch_idx + 1}.xml")
        rough_string = ET.tostring(rss_root, encoding="utf-8")
        reparsed = minidom.parseString(rough_string)
        with open(rss_path, "w", encoding="utf-8") as f:
            f.write(reparsed.toprettyxml(indent="  "))
        
        print(f"âœ… ç”ŸæˆRSSæ‰¹æ¬¡ {batch_idx + 1}: {len(batch_files)} ä¸ªæ–‡ä»¶")

if __name__ == "__main__":
    main()